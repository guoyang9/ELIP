# ELIP: Efficient Language-Image Pre-training with Fewer Vision Tokens

[![arxiv](https://img.shields.io/badge/paper-Arxiv-blue.svg)](https://arxiv.org/abs/2309.16738)

#### Code contribution: Yangyang Guo 60% and Haoyu Zhang 40%.

#### Detailed configuration of each model can be found on each model directory.

### Pre-trained Checkpoints 
If you have a Baidu Drive account, check this <a href="https://pan.baidu.com/s/1C6OP7mJ0nnXQdR1cat22Rw?pwd=rg19">link</a>.

### Citation:
If you found this repo helpful, please consider cite the following paper :+1: :
```ruby
@inproceedings{elip,
  author    = {Guo, Yangyang and Zhang, Haoyu and Nie, Liqiang and Wong, Yongkang and Kankanhalli, Mohan},
  title     = {ELIP: Efficient Language-Image Pre-training with Fewer Vision Tokens},
  booktitle = {arXiv preprint arXiv:2309.16738},
  year      = {2023}}
```
